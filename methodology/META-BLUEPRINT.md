# Meta-Blueprint: AI as Freelance Domain Expert

**Version:** 2.0  
**Purpose:** A reusable framework for engaging AI as a domain expert copilot to design and develop systems from scratch using research-driven decision-making  
**Scope:** Domain-agnostic methodology applicable to any complex system design project  
**Owner:** Human principal (you) + AI copilot (Claude)

---

## 1. The Freelance Domain Expert Model

### 1.1 What This Framework Enables

This meta-blueprint defines how to engage AI as a **freelance domain expert**â€”a copilot that helps you design and build any system from the ground up, even in domains where neither you nor the AI starts with deep expertise.

The model works because:
- **AI can rapidly acquire domain knowledge** through structured deep research
- **Research-backed decisions** prevent the blind spots of pure intuition
- **Explicit methodology** ensures consistent quality across domains
- **Human-AI collaboration** combines your judgment with AI's synthesis capacity

### 1.2 The Engagement Model

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    HUMAN-AI COLLABORATION MODEL                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚   HUMAN (Principal)              AI (Domain Expert Copilot)         â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€              â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€         â”‚
â”‚   â€¢ Defines objectives           â€¢ Acquires domain expertise        â”‚
â”‚   â€¢ Sets constraints             â€¢ Conducts deep research           â”‚
â”‚   â€¢ Makes final decisions        â€¢ Synthesizes findings             â”‚
â”‚   â€¢ Provides feedback            â€¢ Produces blueprints              â”‚
â”‚   â€¢ Approves phase gates         â€¢ Recommends decisions             â”‚
â”‚   â€¢ Owns outcomes                â€¢ Guides implementation            â”‚
â”‚                                                                      â”‚
â”‚                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚
â”‚                         â”‚ SHARED  â”‚                                  â”‚
â”‚                         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                                  â”‚
â”‚                         â”‚Blueprintâ”‚                                  â”‚
â”‚                         â”‚Research â”‚                                  â”‚
â”‚                         â”‚Decisionsâ”‚                                  â”‚
â”‚                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.3 When to Use This Framework

This framework is designed for projects where:

| Characteristic | Why It Matters |
|----------------|----------------|
| **Complex domain** | Requires expertise beyond casual knowledge |
| **High stakes** | Decisions have significant cost/risk implications |
| **Novel system** | No off-the-shelf solution exists |
| **Research-dependent** | Best practices aren't obvious or are evolving |
| **Multi-component** | System has many interacting parts |

**Example domains:**

| Domain | AI Expert Role | System Being Built |
|--------|---------------|-------------------|
| Security Automation | Bug bounty domain expert | Autonomous vulnerability hunter |
| Quantitative Finance | Trading systems architect | Algorithmic trading platform |
| Legal Technology | Legal informatics expert | Contract analysis system |
| Healthcare AI | Clinical decision support expert | Diagnostic assistance tool |
| Developer Tools | DevEx domain expert | AI-powered code review system |
| E-commerce | Marketplace systems expert | Dynamic pricing engine |

### 1.4 The Meta-Blueprint vs Domain Blueprint

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      META-BLUEPRINT (This Document)              â”‚
â”‚                                                                  â”‚
â”‚   WHAT: Methodology for AI-assisted system design                â”‚
â”‚   WHO:  Any human + AI collaboration                             â”‚
â”‚   WHEN: Reused across all projects                               â”‚
â”‚                                                                  â”‚
â”‚   Contains:                                                      â”‚
â”‚   â€¢ Reasoning frameworks                                         â”‚
â”‚   â€¢ Research methodology                                         â”‚
â”‚   â€¢ Decision frameworks                                          â”‚
â”‚   â€¢ Phase management                                             â”‚
â”‚   â€¢ Quality gates                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â”‚ instantiates (one per project)
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   DOMAIN BLUEPRINT (Per Project)                 â”‚
â”‚                                                                  â”‚
â”‚   WHAT: Specification for a specific system                      â”‚
â”‚   WHO:  Built by AI expert, approved by human                    â”‚
â”‚   WHEN: Created fresh for each domain/project                    â”‚
â”‚                                                                  â”‚
â”‚   Contains:                                                      â”‚
â”‚   â€¢ System architecture                                          â”‚
â”‚   â€¢ Component specifications                                     â”‚
â”‚   â€¢ Tool selections                                              â”‚
â”‚   â€¢ Implementation sequences                                     â”‚
â”‚   â€¢ Domain-specific constraints                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Example Instances:
â€¢ ai-bug-bounty-blueprint-v9.html (Security Automation)
â€¢ trading-system-blueprint-v1.html (Quantitative Finance)
â€¢ contract-analyzer-blueprint-v1.html (Legal Technology)
```

---

## 2. Domain Expert Development Lifecycle

### 2.1 The Six Stages

Building domain expertise and a working system follows six stages:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 DOMAIN EXPERT DEVELOPMENT LIFECYCLE                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚   PLANNING PHASE (Claude Project)                                    â”‚
â”‚   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                   â”‚
â”‚                                                                      â”‚
â”‚   Stage 1: SURVEY          Stage 2: DEPTH           Stage 3: SYNTH  â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€         â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚   â€¢ Landscape mapping      â€¢ Deep research          â€¢ Integration   â”‚
â”‚   â€¢ Gap identification     â€¢ Quality gates          â€¢ Blueprint     â”‚
â”‚   â€¢ Priority tiering       â€¢ Source validation      â€¢ Decisions     â”‚
â”‚                                                                      â”‚
â”‚        Output:                  Output:                 Output:      â”‚
â”‚   [Research Plan]          [Research Docs]       [Domain Blueprint] â”‚
â”‚                                                                      â”‚
â”‚   â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ PHASE GATE â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€    â”‚
â”‚                                                                      â”‚
â”‚   DEVELOPMENT PHASE (Claude Code)                                    â”‚
â”‚   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                    â”‚
â”‚                                                                      â”‚
â”‚   Stage 4: IMPLEMENT       Stage 5: VALIDATE       Stage 6: EVOLVE  â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€       â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚   â€¢ Code production        â€¢ Benchmark suite       â€¢ Feedback loop  â”‚
â”‚   â€¢ Module development     â€¢ Ground-truth test     â€¢ Refresh cycles â”‚
â”‚   â€¢ Infrastructure         â€¢ Performance gates     â€¢ Gap remediationâ”‚
â”‚                                                                      â”‚
â”‚        Output:                  Output:                 Output:      â”‚
â”‚   [Working System]         [Validated System]      [Living System]  â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 Stage Descriptions

**Stage 1: SURVEY** â€” Map the landscape
- Identify what expertise is needed
- Catalog existing knowledge and gaps
- Prioritize research topics by tier
- Create research plan with sequencing

**Stage 2: DEPTH** â€” Acquire expertise
- Conduct deep research per topic
- Apply quality gates to each deliverable
- Validate sources and claims
- Build domain knowledge base

**Stage 3: SYNTHESIS** â€” Create blueprint
- Integrate research into coherent architecture
- Make explicit decisions using framework
- Document with WHAT/HOW/WHY/SUCCESS/FAILURE
- Produce versioned domain blueprint

**Stage 4: IMPLEMENT** â€” Build the system
- Translate blueprint to code
- Follow specifications precisely
- Flag deviations back to planning
- Produce working components

**Stage 5: VALIDATE** â€” Prove it works
- Execute benchmark suite
- Test against success criteria
- Verify performance thresholds
- Document actual vs expected

**Stage 6: EVOLVE** â€” Keep it current
- Monitor refresh triggers
- Incorporate operational feedback
- Update research as domain evolves
- Version blueprint and system together

---

## 3. Reasoning Frameworks

### 3.1 ReAct Pattern (Primary Reasoning)

The ReAct (Reasoning + Acting) pattern provides explicit reasoning traces for all decisions:

```
THOUGHT  â†’  What do I need to understand or decide?
ACTION   â†’  What research, tool, or query addresses this?
OBSERVE  â†’  What did I learn from the result?
REFLECT  â†’  How does this update my understanding?
```

**Domain-Agnostic Examples:**

| Domain | Thought | Action | Observe | Reflect |
|--------|---------|--------|---------|---------|
| Security | "Need to understand validation patterns" | Deep research on OOB validation | "Deterministic scripts outperform LLM judgment" | Update blueprint: require script-based validation |
| Trading | "Need to understand latency requirements" | Research HFT infrastructure | "Co-location reduces latency by 10-100x" | Update blueprint: require exchange proximity |
| Legal | "Need to understand contract clause extraction" | Research NLP for legal text | "Fine-tuned models outperform zero-shot by 40%" | Update blueprint: plan for model training |

**Anti-pattern:** Acting without explicit reasoning â†’ unjustified architectural decisions

### 3.2 OODA Loop (Rapid Decisions)

For real-time decisions during implementation:

| Phase | Application |
|-------|-------------|
| **Observe** | Read outputs, errors, benchmark results |
| **Orient** | Map against blueprint specifications |
| **Decide** | Select correction or escalation path |
| **Act** | Implement fix or flag to planning phase |

### 3.3 Task Tree (State Tracking)

Prevent context loss in complex work using hierarchical task tracking:

```
[PROJECT OBJECTIVE]
â”œâ”€â”€ [Research Area 1] âœ“ Complete
â”‚   â”œâ”€â”€ Finding A â†’ Incorporated in blueprint
â”‚   â””â”€â”€ Finding B â†’ Incorporated in blueprint
â”œâ”€â”€ [Research Area 2] â— In Progress
â”‚   â”œâ”€â”€ Sub-topic X âœ“ Complete
â”‚   â””â”€â”€ Sub-topic Y â—‹ Pending
â”œâ”€â”€ [Architecture Decision 1] âœ“ Decided
â”‚   â””â”€â”€ Rationale documented
â””â”€â”€ [Implementation Phase] â—‹ Blocked
    â””â”€â”€ Dependency: Complete Research Area 2
```

**Rules:**
- Only leaf nodes modified during execution
- Parent nodes aggregate child status
- Blocked items state dependencies explicitly
- Completed items preserve reasoning traces

### 3.4 Tripartite Module Design

Separate cognitive functions for clarity:

| Module | Responsibility | Planning Phase | Development Phase |
|--------|---------------|----------------|-------------------|
| **Reasoning** | Strategy, planning, decisions | Primary focus | Reference only |
| **Generation** | Produce artifacts | Blueprints, docs | Code, configs |
| **Parsing** | Interpret, extract insights | Research synthesis | Test analysis |

---

## 4. Research Methodology

### 4.1 Three-Tier Prioritization

Classify all research topics before execution:

| Tier | Criteria | Timing | Examples |
|------|----------|--------|----------|
| **Tier 1: Blocking** | Cannot proceed without | Before any implementation | Core architecture, critical unknowns |
| **Tier 2: Informing** | Significantly impacts quality | Before component work | Tool selection, pattern research |
| **Tier 3: Parallel** | Enhances but doesn't block | Concurrent with development | Optimization, edge cases |

**Decision Rule:** When uncertain, default to higher priority.

### 4.2 Research Lifecycle

```
TRIGGER â†’ CONDUCT â†’ VALIDATE â†’ INTEGRATE â†’ VERSION â†’ SCHEDULE
   â”‚          â”‚          â”‚           â”‚          â”‚          â”‚
   â”‚          â”‚          â”‚           â”‚          â”‚          â””â”€â–º Set refresh date
   â”‚          â”‚          â”‚           â”‚          â””â”€â–º Bump blueprint version
   â”‚          â”‚          â”‚           â””â”€â–º Update blueprint sections
   â”‚          â”‚          â””â”€â–º Pass 5 quality gates
   â”‚          â””â”€â–º Deep research execution
   â””â”€â–º Gap found, refresh due, or trigger event
```

### 4.3 Quality Gates

Before accepting any research as complete:

**Gate 1: Citation Density**
- [ ] â‰¥3 primary sources per major section
- [ ] Sources: academic papers, official docs, production case studies
- [ ] Marketing materials do NOT count as primary sources
- [ ] URLs provided for verification

**Gate 2: Implementation Readiness**
- [ ] Working code samples (not pseudocode)
- [ ] Configuration files with version numbers
- [ ] Schemas or type definitions where relevant
- [ ] Infrastructure manifests if applicable

**Gate 3: Quantitative Evidence**
- [ ] Performance benchmarks with methodology
- [ ] Cost analysis with pricing sources
- [ ] Success/failure rates with sample sizes
- [ ] Statistical measures where appropriate

**Gate 4: Failure Mode Analysis**
- [ ] Top 5 failure modes per component
- [ ] Specific mitigations documented
- [ ] Known limitations acknowledged
- [ ] Edge cases identified

**Gate 5: Decision Framework**
- [ ] Clear recommendations (not "it depends")
- [ ] Decision criteria explicit
- [ ] Alternatives compared with tradeoffs
- [ ] Context for when to use alternatives

### 4.4 Refresh Triggers

| Trigger Event | Action |
|---------------|--------|
| Competitor move (funding, launch) | Market analysis refresh |
| Major framework/tool release | Integration research update |
| Regulatory/compliance change | Constraints review |
| Implementation failure | Root cause research |
| Quarterly calendar | Tier 2 systematic review |
| Monthly calendar | Tier 3 scan for new patterns |

---

## 5. Decision Framework

### 5.1 The 5-Part Decision Template

Every architectural decision must document:

```markdown
## [Decision Topic]

**WHAT**: One-sentence responsibility statement

**HOW**: Specific implementation
- Tool/technology: [name + version]
- Configuration: [key settings]
- Code reference: [file or inline sample]

**WHY**: Research-backed rationale
- Primary source: [citation]
- Supporting source: [citation]
- Compared to: [rejected alternatives and why]

**SUCCESS**: Measurable criteria
- Metric: [specific threshold]
- Test method: [how to verify]

**FAILURE**: Known limitations
- Mode 1: [description] â†’ Mitigation: [approach]
- Mode 2: [description] â†’ Mitigation: [approach]
- Hard limits: [what this cannot do]
```

### 5.2 Decision Anti-Patterns

| Anti-Pattern | Problem | Correction |
|--------------|---------|------------|
| "It depends" | No actionable guidance | Enumerate contexts with specific recommendations |
| No citation | Unverified claims | Require â‰¥1 source per claim |
| Pseudocode only | Not implementable | Require working code |
| No failure modes | Blind to risks | Require top 5 scenarios |
| Vague metrics | Can't validate | Require specific thresholds |

### 5.3 Specificity Anchors

Replace vague terms with measurable specifications:

| Vague | Specific (Security Domain) | Specific (Trading Domain) | Specific (Legal Domain) |
|-------|---------------------------|--------------------------|------------------------|
| "fast" | < 3 min per target | < 10ms order latency | < 2s per contract |
| "accurate" | 0 false positives | < 0.1% tracking error | > 95% clause extraction |
| "scalable" | 10K targets/day | 1M orders/day | 100K contracts/month |
| "cost-effective" | < $0.30/target | < $0.001/order | < $0.10/contract |
| "reliable" | 99.9% uptime | 99.99% uptime | 99.5% uptime |

---

## 6. Phase Separation

### 6.1 Two-Phase Model

| Aspect | Planning Phase | Development Phase |
|--------|---------------|-------------------|
| **Environment** | Claude Project | Claude Code |
| **Focus** | Strategy, architecture, research | Implementation, testing |
| **Outputs** | Blueprints, decisions, CLAUDE.md | Code, configs, systems |
| **Reasoning** | Exploratory, divergent | Convergent, task-focused |
| **Context** | Accumulated across sessions | Fresh per session |
| **Risk tolerance** | Higher (exploring options) | Lower (must work) |

### 6.2 Planning Phase Responsibilities

**AI Domain Expert owns:**
- Research synthesis and prioritization
- Blueprint creation and maintenance
- Architectural decision-making
- Strategy and roadmap development
- Gap analysis and risk assessment
- Quality gate verification
- CLAUDE.md generation for handoff

**Planning Phase outputs:**
1. **Domain Blueprint** â€” Comprehensive system specification
2. **CLAUDE.md** â€” Implementation constitution for development phase
3. **Research Documents** â€” Deep dive artifacts
4. **Decision Log** â€” Rationale preservation

### 6.3 Development Phase Responsibilities

**AI Implementation Agent owns:**
- Code production per specifications
- Module development
- Infrastructure configuration
- Testing and debugging
- Benchmark execution
- Performance optimization

**Development Phase inputs:**
1. **CLAUDE.md** â€” Constitution defining constraints
2. **Blueprint references** â€” Architecture context
3. **Code templates** â€” Starter implementations

### 6.4 Phase Transition Gates

Before transitioning from Planning â†’ Development:

**Gate A: Architecture Completeness**
- [ ] All Tier 1 research complete
- [ ] Core components have 5-part decisions
- [ ] Infrastructure topology documented
- [ ] Data schemas defined

**Gate B: Implementation Readiness**
- [ ] Working code samples exist (not pseudocode)
- [ ] Dependency versions locked
- [ ] Infrastructure configurations ready
- [ ] Test strategy defined

**Gate C: Handoff Artifacts**
- [ ] CLAUDE.md generated and validated
- [ ] Blueprint version tagged
- [ ] Known gaps documented with workarounds
- [ ] Success criteria measurable

**Gate D: Risk Acknowledgment**
- [ ] Top failure modes documented
- [ ] Human approval points identified
- [ ] Rollback strategy defined
- [ ] Budget/resource limits set

---

## 7. Skill Architecture

### 7.1 Skill Categories

Skills are organized by phase and function:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         SKILL ARCHITECTURE                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚   PLANNING PHASE SKILLS              DEVELOPMENT PHASE SKILLS        â”‚
â”‚   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•              â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•        â”‚
â”‚                                                                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚   â”‚ research-strategist â”‚            â”‚ claude-code-constitution â”‚    â”‚
â”‚   â”‚ â€¢ Tier prioritizationâ”‚            â”‚ â€¢ CLAUDE.md consumption â”‚    â”‚
â”‚   â”‚ â€¢ Gap analysis       â”‚            â”‚ â€¢ Constraint enforcementâ”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚   â”‚ deep-research       â”‚            â”‚ implementation-patterns â”‚     â”‚
â”‚   â”‚ â€¢ Prompt crafting   â”‚            â”‚ â€¢ Code templates     â”‚        â”‚
â”‚   â”‚ â€¢ Quality gates     â”‚            â”‚ â€¢ Testing patterns   â”‚        â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚   â”‚ blueprint-architect â”‚            â”‚ validation-framework â”‚        â”‚
â”‚   â”‚ â€¢ Structure design  â”‚            â”‚ â€¢ Benchmark executionâ”‚        â”‚
â”‚   â”‚ â€¢ Version managementâ”‚            â”‚ â€¢ Performance gates  â”‚        â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                           â”‚
â”‚   â”‚ decision-documenter â”‚                                           â”‚
â”‚   â”‚ â€¢ 5-part template   â”‚                                           â”‚
â”‚   â”‚ â€¢ Rationale capture â”‚                                           â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                           â”‚
â”‚                                                                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                           â”‚
â”‚   â”‚ phase-transition    â”‚â—„â”€â”€â”€ BRIDGE SKILL                          â”‚
â”‚   â”‚ â€¢ Gate verification â”‚                                           â”‚
â”‚   â”‚ â€¢ CLAUDE.md generationâ”‚                                         â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                           â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 7.2 Planning Phase Skills

| Skill | Purpose | Triggers |
|-------|---------|----------|
| `research-strategist` | Prioritize and sequence research | "What should we research?", "Identify gaps" |
| `deep-research` | Craft expert research prompts | "Research X", "Deep dive on Y" |
| `blueprint-architect` | Create/maintain domain blueprints | "Create blueprint", "Update architecture" |
| `decision-documenter` | Apply 5-part decision framework | "Document decision", "Why did we choose X?" |
| `blueprint-evaluator` | Compare architectural variations | "Evaluate approaches", "Compare options" |

### 7.3 Development Phase Skills

| Skill | Purpose | Triggers |
|-------|---------|----------|
| `claude-code-constitution` | Consume CLAUDE.md, enforce constraints | Session start |
| `implementation-patterns` | Apply code templates and patterns | "Implement X", "Build Y" |
| `validation-framework` | Execute benchmarks, verify thresholds | "Test X", "Validate Y" |

### 7.4 Bridge Skills

| Skill | Purpose | Triggers |
|-------|---------|----------|
| `phase-transition` | Verify gates, generate CLAUDE.md | "Ready for development?", "Generate handoff" |

---

## 8. Blueprint Architecture

### 8.1 Progressive Disclosure Structure

Domain blueprints follow three layers:

**Layer 1: Executive Summary** (< 2 min read)
- System purpose in one sentence
- Key metrics and thresholds
- High-level architecture diagram
- Current status and version

**Layer 2: Pipeline Overview** (< 15 min read)
- Component descriptions (1 paragraph each)
- Data flow between components
- Tool selections with brief rationale
- Success criteria per component

**Layer 3: Deep Specifications** (Reference as needed)
- Full 5-part decisions per component
- Working code samples
- Failure mode analysis
- Complete research citations

### 8.2 Blueprint Versioning

| Change Type | Version Bump | Example |
|-------------|--------------|---------|
| Major architectural change | X.0 â†’ (X+1).0 | New component added |
| Significant refinement | X.Y â†’ X.(Y+1) | Tool selection changed |
| Minor correction | Changelog only | Typo, clarification |

### 8.3 Blueprint â†’ CLAUDE.md Translation

The CLAUDE.md file extracts implementation essentials:

| Blueprint Section | CLAUDE.md Section |
|-------------------|-------------------|
| Executive Summary | Core Objective |
| Critical Thresholds | Architectural Constraints |
| Tool Selections | Approved Tools |
| Human Approval Matrix | Security Protocols |
| Phase 1 Implementation | Immediate Priorities |
| Success Criteria | Validation Requirements |

**CLAUDE.md Constraints:**
- Maximum 500 lines (context efficiency)
- No research citations (implementation focus)
- Working code samples only
- Explicit safety boundaries
- Clear scope limitations

---

## 9. Communication Standards

### 9.1 AI Expert Response Structure

```
[DIRECT ANSWER]      â€” Conclusion first (1-2 sentences)
[SUPPORTING EVIDENCE] â€” Research citations, data points
[IMPLEMENTATION PATH] â€” Concrete next steps
[CAVEATS]            â€” Known limitations, uncertainties
```

### 9.2 Confidence Expression

| Level | Expression | Basis |
|-------|------------|-------|
| **High** (>90%) | "X is the correct approach" | Multiple production sources |
| **Medium** (60-90%) | "X is likely best because..." | Limited sources, strong reasoning |
| **Low** (<60%) | "Options include X, Y, Z..." | Insufficient evidence |
| **Unknown** | "Research needed before deciding" | No evidence available |

### 9.3 Citation Format

```
[Source Type]: [Title] â€” [Key Finding]
```

Examples:
- **Academic**: AuthorName (Venue Year) â€” Key finding
- **Production**: Company Blog â€” Implementation pattern
- **Documentation**: Tool vX.Y Docs â€” Configuration detail
- **Benchmark**: Study Name â€” Quantitative result

### 9.4 Disagreement Protocol

When AI expert disagrees with human principal:

1. **State disagreement clearly**: "I recommend against X because..."
2. **Provide evidence**: Cite research supporting the concern
3. **Offer alternatives**: "Instead, consider Y which..."
4. **Defer to principal**: "However, this is your decision. If you choose X, here's how to mitigate risks..."

---

## 10. Meta-Blueprint Maintenance

### 10.1 Evolution Triggers

Update this meta-blueprint when:
- A methodology pattern consistently fails
- A new reasoning framework proves superior
- Phase boundaries need adjustment
- Quality gates require recalibration
- A new project reveals transferable improvements

### 10.2 Versioning

| Version | Scope |
|---------|-------|
| 1.x | Initial methodology |
| 2.x | Freelance expert model formalized |
| 3.x | Fundamental framework revision |

### 10.3 Validation Criteria

The meta-blueprint succeeds if:
1. **Outcome quality**: Projects using it produce working systems
2. **Efficiency**: Avoids common pitfalls (scope creep, unjustified decisions)
3. **Transferability**: Applies successfully to different domains
4. **Learnability**: New projects ramp up faster than previous ones

---

## Appendix A: Quick Reference

### Planning Phase Checklist

```
â–¡ Define project objectives and constraints
â–¡ Survey domain landscape
â–¡ Tier research topics (1/2/3)
â–¡ Conduct Tier 1 research
â–¡ Pass all 5 quality gates per topic
â–¡ Apply 5-part decision framework
â–¡ Create domain blueprint
â–¡ Verify phase transition gates
â–¡ Generate CLAUDE.md handoff
```

### Development Phase Checklist

```
â–¡ Load CLAUDE.md constitution
â–¡ Reference blueprint for context
â–¡ Implement per specifications
â–¡ Test against success criteria
â–¡ Document any deviations
â–¡ Flag gaps back to planning phase
â–¡ Execute validation benchmarks
```

### Decision Template

```markdown
## [Component/Decision Name]

**WHAT**: [One sentence]

**HOW**: 
- Tool: [name vX.Y]
- Config: [key settings]
- Code: [reference or sample]

**WHY**:
- Source: [citation]
- vs Alternatives: [why not X, Y]

**SUCCESS**:
- Metric: [threshold]
- Test: [method]

**FAILURE**:
- Mode: [description] â†’ Mitigation: [approach]
- Limits: [what cannot do]
```

---

## Appendix B: Glossary

| Term | Definition |
|------|------------|
| **Meta-Blueprint** | Domain-agnostic methodology for AI-assisted system design |
| **Domain Blueprint** | Project-specific system specification |
| **Domain Expert** | AI role acquiring and applying specialized knowledge |
| **Principal** | Human decision-maker and project owner |
| **CLAUDE.md** | Implementation constitution for development phase |
| **Phase Gate** | Criteria required before phase transition |
| **Quality Gate** | Criteria required before accepting research |
| **Refresh Trigger** | Event initiating research update |
| **Specificity Anchor** | Concrete metric replacing vague term |
| **Progressive Disclosure** | Layered documentation (summary â†’ detail) |
| **Tripartite Design** | Reasoning/Generation/Parsing separation |

---

## Appendix C: Example Domain Instantiations

### Security Automation (Current Project)
- **Blueprint**: `ai-bug-bounty-blueprint-v9.html`
- **Domain**: Autonomous vulnerability discovery
- **Key Thresholds**: < $0.30/target, 0 false positives, < 3 min discovery
- **Status**: Planning phase complete, ready for development

### Future Instantiation Template
```
Domain: [Name]
Blueprint: [filename]
AI Expert Role: [specialization]
Key Thresholds:
  - [Metric 1]: [Value]
  - [Metric 2]: [Value]
Human Principal: [Name/Role]
Status: [Stage]
```

---

*Meta-Blueprint v2.0 | Freelance Domain Expert Framework*  
*Last Updated: December 2024 | Review: Quarterly*
